### 상황별 데이터 전처리 로드맵

1. 웹사이트 로그기록
   1. 각 웹사이트를 접속한 고객들이 접속한 모든 주소를 추출하여 연관분석, Lift값을 계산하여 이를 X변수로 설정한다.
   2. 변수 : N일전 방문 URL별 Lift값
2. 불량판정을 위한 다양한 공정의 타임스탬프 센서값
   1. 같은 공정 병합
   2. 소요시간 Shift하여 2차 병합( 1개의 마트 생성 )
   3. 정상 기동시간에 해당하는 데이터만 추출
3. 불량판정을 위한 하나의 공정의 다수의 센서값
   1. 각 변수를 모두 독립변수로 하여 지도학습
   2. 중간 데이터로 품질 예측하려면 데이터 처리방안
      1. 현재값을 유지한다고 가정
      2. PCA모델링으로 예측값을 채움
      3. 시계열 모델링하여 예측값을 채움
4. 퇴직예측
   1. 퇴사여부로 지도학습
   2. N개월 단위로 전체기간에 대해 검증
   3. 불균형 데이터 이므로 클래스 불균형 처리
      1. Under, up샘플링, SMOTE, GAN
      2. 모델 평가시 Precision과 Recall도 고려
5. 시간 단위 행동로그로 루틴 묶기
   1. 짧은 구간별 행동그룹 생성
   2. 발생빈도 높은 것만 반복 행동 그룹
   3. 행동 선후관계를 따져 지도학습

### 상황별 분석 모델링 로드맵

1. 인자추출 : 중요인자 선별
   1. 불량 영향인자 도출
   2. 설비 이상 모니터링

2. 상관분석 : 인자들간 상관성 함수표현
   1. 최적 레시피 도출

3. 연관성분석 : 두 인자간 연관성 산출
   1. 혐의설비 도출

4. 군집분석 : 유사한 패턴 묶기
   1. 고객군 Segmentation

5. 분류분석 : 특정 집단 데이터 패턴 학습
   1. 불량유형 분류

6. 예측분석 : 특정 인자 값이 얻어지기 전에 예측
   1. 셀아웃

1. 예시) 신제품 잠재고객 타켓팅모델 개발 및 운영방안 도출
   1. 마케팅타켓팅을위한ML모델개발(대상/비대상판별을위한지도학습모형)
   2. 학습시offer 수락/거절이력을Y로정의하고 모델링해야함
   3. 수락/거절이력이 없는경우 가입여부를 Y로정의함
   4. 모델은 매월신규실적이집계되는 말일날 신규실적데이터를 포함한 최근x개월데이터를 활용하여 재학습하고 다음달 마케팅 타켓을 선정함
   5. 기존6개월간의마케팅활동결과수락/거절이력이존재하지않을경우다른분석설계를고려해야함
   6. 수락비율이너무낮을경우지도학습모델이잘학습되지않을가능성이존재함
   7. 재학습주기와모델사용주기가결정되기이전에학습/추론이시스템화되어야함(환경준비미흡가능성)
2. 예시) 모바일 광고 유형에 따른 클릭 CTR 예측 모델
   1. 설명력높은 트리나 LM모델 사용


## 분석 시나리오 작성 순서 및 방안

**문제의 요구에 따라 해당 기능을 제공하는 클라우드 플랫폼을 언급할것**



0. 반응변수의 분포가 어떤가?

   - 반응변수가 categorical 이라면 클래스 불균형 문제가 있는가, 불균형 문제가 있다면 -> undersampling oversampling 등등 기법 활용

   - 반응변수가 numeric 이라면 분포 확인 -> skewed(주로 skewed to the right) 되어 있다면 예측력 상승을 위해 log transpormation 과 같은 조치 필요.

   - 추가적으로 ,반응변수를 지정해서 사용해야 하는 경우라면

     어떤 "기준" 으로 반응변수를 라벨링 해 주어야 할지 여부도 적어 주어야 한다. (ex. 1 이상이면 불량, 이하면 양품, 시간별 불량률인지, 일별 불량률인인지 등등)



1. 설명변수로 무엇을 사용 할 것인가 ? / 데이터 마트 구성 

   - 분석 목적이 무엇이냐에 따라(target이 무엇이냐) 데이터 마트를 구성하는 행의 기준이 시간일수도, 건수일수도 기타등등일수도 있음. 

   - 수치형 변수는 무엇이고, 범주형 변수는 무엇인지

     -> 수치형 변수에 대해서는 단위를 맞춰주는 표준화 작업 필요, 범주형 변수는 one-hot-encoding 필요

   - 변수에 결측치가 존재하는지

     -> 존재한다면 결측값 처리를 어떻게 진행 할 것인지 

      많지 않다면 결측값이 존재하는 행을 삭제, 변수에서 결측값의 비율이 90%를 넘어가면 변수 삭제 고려 

     적절하게 존재한다면 imputation 시행

   - 파생 변수 생성이 필요하다면? 

     -> 사용자 별 요약 통계량(min, max, median, mean 3q 등등)을 생성하는 것이 가장 일반적임( 특히, 시계열 분석에서)

     통계량을 생성 할 시에는 축을 여러가지로 고려 해 보는 것이 좋은데, 첫번째는 시간순(day, week, month )으로 통계량을 생성 하는 것이고 두번째는 주요 카테고리 별 요약 통계량을 생성 하는 것임. (ex, 설명변수로 품목 변수가 있다면 품목 별 요약 통계량 생성)

     -> 특히 시계열 분석에서 결합하고자 하는 설명변수들의 시간 단위(초/분/시간)이 맞지 않은 경우가 있음. 그런 경우에는 상위 시간에 맞춰 하위 시간을 통합하여 결합을 진행하여야 함. 

     ex) 초 단위 변수와 분 단위 변수를 결합해야 한다면 초 단위 데이터를 분 단위 데이터로 변경하여야 하고, 이를 진행하기 위한 요약 통계량을 생성 하는 것이 좋다. (Min / Max / Mean / Mode)

     -> 파생변수 생성시, Train 에서 표준화된 파생변수를 정의하였다면, test 셋의 파생변수는 train셋의 평균과 표준편차를 이용하여 계산되어야 함. 

   - 데이터간 merge를 통해 설명변수를 추가 구성 해야 할 때?

     -> 키 값을 늘 생각하며 언급 해 주는 것이 좋음! 어떤 변수를 기준으로 데이터를 병합 할 것인지

   - 설명변수를 고려 할 때는 ID 및 시간변수를 항상 고민하기 / 텍스트로 이루어진 설명변수도 고민하기(범주를 묶는식으로 전처리를 진행할지, 아예 변수를 사용하지 않을 지 등등)

   - 설명변수를 일부만 사용해야 할 때는 어떤걸 기준으로 변수 선택을 할지 적어주기(ex, 회귀의 경우면 stepwise, tree면 importance기준 등등)

   - 행간의 독립성이 지켜지고 있는가?

     -> 행간 독립성을 위해 wide_form 형태의 데이터마트를 구성하는 것이 좋음. -> 데이터 셔플 역시 용이해져서 train/valid/test 구성에도 용이함. 

     

2. 모델은 무엇을 사용 할 것인가 ?

   - 예측이 중요한지/ 설명력이 중요한지 

     설명력이 중요한 모형 -> GLM/Tree 모형

     예측력이 중요한 모형 -> 앙상블 모형, 뉴럴넷

     -> ~~ 한 분석 목적에 따라 "'~" 이 좋은 모형을 사용하도록 하겠다 라는 가정을 적어주고 시작하면 됨. 

     ex) 불량 요인 분석이기 때문에 "설명력" 에 초점을 맞춘 모형을 사용하도록 하겠다

   - 설명변수의 타입이 어떤지

     주로 범주형 변수라면 -> GLM, Tree 모형 (뉴럴넷은 차원이 너무 커져서 힘듦)

     주로 수치형 변수라면 -> GLM, 뉴럴넷, 앙상블

     범주+ 수치 혼합 -> 대부분의 모형 다 가능

     결측값이 많이 존재하는 변수들이 있다면 

     -> Xgboost, LightGBM 은 결측값을 loss gain 이 큰 방향으로 밀어버리면서 처리

     -> NaiveBayes 는 결측값 무시

     -> rpart 의 Decision Tree 는 Surrogate feature(대체변수) 를 사용하여 모델링

   - 한 라벨의 데이터만 쓰는지 모든 라벨을 다 쓰는지?

     ex) 고객별로 정상 사용 패턴과 비정상 패턴의 차이가 대단히 클때, 정상 사용 건수만 가지고 모델을 구축(isolation forest, autoencoder 등등) 한 뒤, 정상에서 벗어난 데이터가 신규로 유입될 경우 비정상으로 판단.

   - 학습 기간은 어떻게 할 것인지?

     단순히 x변수들을 가지고 모델링을 한다 가 아니고 몇달간의 데이터를 사용해서~ 와 같이 학습 기간을 지정해 주는 것이 필요할 때가 있음.

     

3. 검증은 어떻게 진행 할 것인가? 

   - 하이퍼 파라미터 튜닝 시행 ->  검증의 신뢰도를 위해 5fold or 10fold Cross Validation 진행

   - 모델링 목적에 따라 MAPE/RMSE/Precision/Recall/accuracy 등등의 지표를 보고 판단

   - 추가적으로 마케팅 데이터와 같은 경우는 A/B test를 진행하여 모델의 효력을 검증하는 경우도 있음

   - 단순히 통계적인 검증방법 뿐만 아니라, 현업의 업무와 관련해서 어떤식으로 검증을 진행 할 것인지에 대한 부분도 적어주어야 함.

   - 시간에 따른 모델인 경우, 학습기간 및 테스트 기간을 moving 하여 여러 번 검증하여 robust 한 모델을 만드는 것이 필요함.

     

4. 운영, to-be 이미지(MLOps?)

   - 구축한 모델 파일을 던져주는 것에서 끝나는게 아니라, 해당 모델을 어떻게 운영하고 배포하고 배치작업을 할 지에 대한 고려가 추가적으로 필요함. 

   - MLDL 사용해서 진행한다고 하면 될듯. 

     

5. 기타

   - 시간에 따라 반응변수에 유의미한 차이가 있는 시계열 모형의 경우, Moving windows 의 검증 방식이 필요함.

   - Arima 모형을 사용한 경우에는, 잔차에 자가상관이 없는지를 check 해야함.(포트만토 검정)

   - 추천 시스템의 경우 분석 목적에 따라 userbased CF인지 Itembased CF인지 고려, 그냥 헷갈리면 SVD 쓴다 하면될듯.

   - 추천시스템 평가 지표로는 map@k, recall@k와 같은 지표들을 주로 사용. 

   - 머신러닝 모델의 예측력이 좋아질수록, Bias는 상승, Variance는 감소. 반대로 예측력이 낮아진 간단한 모델일수록 Bias는 작지만 Variance가 커짐.
   - Tree 모델을 사용하는 경우, 외삽이 안되는거지 예측은 모두 가능함.(말장난 주의)
   - shap value의 절댓값의 평균값이 각 변수의 중요도. / shap value와 base value의 합이 모델의 옟측값

   

6. 평가 지표

   - precision : 1이라고 분류된 것중 실제 1의 비율 (확실한 것만 1이라고 분류한다)
   - recall : 실제 1중에 1이라고 분류 된 것의 비율
   - Multiclass의 경우 micro, macro precision/recall임
